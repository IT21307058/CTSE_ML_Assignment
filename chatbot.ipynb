{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTSE Lecture Notes Load\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "The following code snippet is used to load all PDF files from a specific folder (`./ctse_lectures`) into a list called `docs`.\n",
    "\n",
    "1. **Importing Libraries:**\n",
    "    - `os`: A module that provides a way to interact with the operating system. Here, it is used to list the files in the given directory.\n",
    "    - `PyPDFLoader`: A class from the `langchain_community.document_loaders` module that is used to load PDF documents.\n",
    "\n",
    "2. **Setting Folder Path:**\n",
    "    - The folder containing the PDF files is specified as `./ctse_lectures`.\n",
    "\n",
    "3. **Initialize List `docs`:**\n",
    "    - An empty list `docs` is initialized to store the loaded documents.\n",
    "\n",
    "4. **Looping through Files in the Folder:**\n",
    "    - The code loops through each file in the directory `./ctse_lectures` using `os.listdir()`.\n",
    "    - It checks whether the file ends with the `.pdf` extension using the `endswith()` method.\n",
    "\n",
    "5. **Loading PDFs:**\n",
    "    - If the file is a PDF, it uses `PyPDFLoader` to load the PDF and then extends the `docs` list with the contents of the loaded PDF.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Outcome\n",
    "After running this code, all the PDF documents in the folder will be loaded into the `docs` list, and you can use the documents for further processing or analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load all PDFs from the folder\n",
    "folder_path = \"./ctse_lectures\"\n",
    "docs = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(folder_path, filename))\n",
    "        docs.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Vector Store\n",
    "\n",
    "#### 1. **Updated Imports**\n",
    "The code imports the necessary libraries:\n",
    "- `FAISS` from `langchain_community.vectorstores`: Used for creating a vector store.\n",
    "- `OpenAIEmbeddings` from `langchain_community.embeddings`: Used to generate embeddings with OpenAI.\n",
    "- `RecursiveCharacterTextSplitter` from `langchain_text_splitters`: Used to split documents into chunks.\n",
    "- `load_dotenv` from `dotenv`: Used to load environment variables from a `.env` file.\n",
    "- `os`: Used to interact with the operating system, particularly to fetch environment variables.\n",
    "\n",
    "#### 2. **Loading Environment Variables from the `.env` file**\n",
    "The `load_dotenv()` function is called to load environment variables, specifically the OpenAI API key, from the `.env` file. This is a secure way to manage sensitive data such as API keys.\n",
    "\n",
    "#### 3. **Retrieve OpenAI API Key**\n",
    "The OpenAI API key is fetched using the `os.getenv()` function by specifying the environment variable `OPENAI_API_KEY` that contains the API key. This ensures the key is not hard-coded into the script.\n",
    "\n",
    "#### 4. **Splitting Documents into Chunks**\n",
    "The `RecursiveCharacterTextSplitter` is used to break documents into smaller chunks. The `chunk_size` is set to 1000 characters, and the `chunk_overlap` is set to 100 characters, ensuring that documents are split into manageable pieces for processing.\n",
    "\n",
    "#### 5. **Creating the Vector Store**\n",
    "The `OpenAIEmbeddings` class is used to create embeddings from the split documents. These embeddings are then stored in a **FAISS** vector store, allowing for efficient retrieval and similarity searches.\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome:\n",
    "After running this code, the documents are split into chunks, embeddings are generated, and they are stored in the FAISS vector store. You can now use this vector store to perform similarity searches and retrieve relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7400\\721475220.py:19: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n"
     ]
    }
   ],
   "source": [
    "# Updated imports\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv  \n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve OpenAI API Key from environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Split documents into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# Create vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Querying the Vector Store with OpenAI API using RetrievalQA\n",
    "\n",
    "#### 1. **Updated Imports**\n",
    "The following libraries are imported:\n",
    "- **RetrievalQA** from `langchain.chains`: This is used to create a Question-Answering (QA) system based on a retrieval model.\n",
    "- **ChatOpenAI** from `langchain_openai`: This is used to create the OpenAI model that generates responses using the OpenAI API.\n",
    "- **load_dotenv** from `dotenv`: This is used to load environment variables from a `.env` file, which helps keep sensitive information like API keys secure.\n",
    "- **os**: This standard Python module is used to interact with the operating system, specifically to fetch the environment variables.\n",
    "\n",
    "#### 2. **Loading Environment Variables from `.env` File**\n",
    "The `load_dotenv()` function loads environment variables from a `.env` file. This ensures that the API key is stored securely and not hardcoded into the script.\n",
    "\n",
    "#### 3. **Retrieving the OpenAI API Key**\n",
    "The OpenAI API key is retrieved from the environment variables using `os.getenv()`. The key is stored in the variable `openai_api_key`, which is passed to the `ChatOpenAI` class.\n",
    "\n",
    "#### 4. **Setting Up the OpenAI Model and Retriever**\n",
    "The `ChatOpenAI` class is initialized with the API key to create an LLM (Language Model). The retriever is created from the `vectorstore`, which will be used to retrieve relevant documents based on queries.\n",
    "\n",
    "#### 5. **Setting Up the RetrievalQA Chain**\n",
    "The `RetrievalQA` chain is created by combining the LLM and the retriever. This allows the system to perform question answering based on the retrieved documents.\n",
    "\n",
    "#### 6. **Example Query**\n",
    "The code sends an example query: `\"What is the CAP THEOREM?\"` to the `qa.run()` method, which uses the LLM and the retriever to generate a response.\n",
    "\n",
    "#### 7. **Formatting the Response**\n",
    "Finally, the response is formatted using `textwrap.fill()` to ensure that the output text is displayed neatly, with a specified width of 100 characters.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Outcome:\n",
    "After executing this code, the system will return an answer to the query \"What is the CAP THEOREM?\" by retrieving relevant documents, processing them with the OpenAI model, and displaying the result in a formatted manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7400\\1890227336.py:19: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa.run(\"What is the CAP THEOREM?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CAP Theorem, also known as Brewer's Theorem, is a fundamental concept in distributed systems. It\n",
      "states that in a distributed system, it is impossible to simultaneously achieve all three of the\n",
      "following properties: consistency, availability, and partition tolerance. Instead, a system can only\n",
      "have at most two out of these three properties at any given time.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "import textwrap\n",
    "from dotenv import load_dotenv  # Import dotenv to load environment variables\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve OpenAI API Key from environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Example query\n",
    "response = qa.run(\"What is the CAP THEOREM?\")\n",
    "print(textwrap.fill(response, width=100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
